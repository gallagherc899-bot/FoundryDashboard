Streamlined Dashboard Plan

Total: 4 Panels (or Tabs)

Prognostic Model (Predict & Diagnose)

RQ1 â€“ Model Validation & Predictive Performance

RQ2 â€“ Reliability & PHM Equivalence

RQ3 â€“ Operational Impact (Scrap, TTE, ROI)

And youâ€™re absolutely right:

The sidebar can be removed (or minimized).

The reliability metrics (MTTR, Availability, Reliability) can be auto-calculated and displayed directly.

The model can automatically set the Scrap Threshold = average scrap % for the selected part ID.

ğŸ§­ OVERALL FLOW (How the model behaves)

When the user selects a Part ID, the dashboard automatically:

Retrieves the average scrap % for that part â†’ sets this as the threshold (no manual entry).

Runs the trained model using the 6â€“2â€“1 rolling window and Random Forest ensemble.

Displays predictions and diagnostics (process causes, defect probabilities, reliability metrics).

Auto-updates the reliability, validation, and impact panels accordingly.

No user tuning needed â€” just â€œSelect Part â†’ View Prognostic Insights.â€

ğŸ”¹ Panel 1: Prognostic Model (Predict & Diagnose)

Rename to: Prognostic Model (Predict & Diagnose)

Purpose

To show how the model predicts where and why scrap is likely to occur.

Contents
Section	Description	Display Element
Part & Threshold Summary	Show Part ID, weight, order size, avg. scrap %, auto-threshold = avg. scrap	Top info card
Predicted Scrap Probability	Modelâ€™s predicted scrap risk (%) for the next order/run	Gauge or % card
Predicted Top Process(es) Causing Scrap	Shows top 2â€“3 likely process sources (from Pareto/importance)	Pareto bar chart
Defect Importance	Feature importance from Random Forest	Horizontal bar chart
Reliability Snapshot	MTTS, Î», R(1), A displayed in summary cards	Metric cards
Default Settings

Threshold: Auto = average scrap %

MTTR: Fixed at 1.0 (unless changed)

Rolling Window: 6â€“2â€“1 (hidden)

Part filtering: Weight Â±10%

âœ… Outcome: This tab tells â€œwhatâ€™s about to go wrong and whyâ€ â€” in plain terms.

ğŸ”¹ Panel 2: RQ1 â€“ Model Validation & Predictive Performance

Research Link:
RQ1: Does MTTS-integrated ML achieve effective prognostic recall (â‰¥80%) for scrap prediction?
H1: MTTS integration will achieve â‰¥80% recall, consistent with effective PHM systems.

Purpose

To prove that the modelâ€™s predictions are valid and reliable per PHM standards.

Contents
Section	Description	Display Element
ROC Curve	Model discrimination ability (AUC â‰¥ 0.80 target)	ROC curve plot
Precisionâ€“Recall Curve	Balance of false positives vs. recall	PR curve
Calibration Curve	Predicted vs. actual scrap probability	Line plot
Summary Metrics	Recall, AUC, Precision, Brier Score	KPI cards
Validation Statement	Text field: â€œModel achieves PHM-equivalent recall â‰¥80%, validating RQ1.â€	Text summary

âœ… Outcome: Shows that your model is both predictive and calibrated, confirming RQ1 and H1.

ğŸ”¹ Panel 3: RQ2 â€“ Reliability & PHM Equivalence

Research Link:
RQ2: Can sensor-free SPC-native ML achieve â‰¥80% of sensor-based PHM prediction performance?
H2: SPC-native ML achieves â‰¥80% PHM-equivalent recall without sensors.

Purpose

To prove that your sensor-free model performs on par with PHM expectations and reliability logic.

Contents
Section	Description	Display Element
Reliability Curve	
ğ‘…
(
ğ‘›
)
=
ğ‘’
âˆ’
ğ‘›
/
ğ‘€
ğ‘‡
ğ‘‡
ğ‘†
R(n)=e
âˆ’n/MTTS
	Line graph
MTTS & Î» Summary	Show MTTS, hazard rate, reliability at 1, 5, and 10 runs	KPI table
Availability Curve	
ğ´
=
ğ‘€
ğ‘‡
ğ‘‡
ğ‘†
ğ‘€
ğ‘‡
ğ‘‡
ğ‘†
+
ğ‘€
ğ‘‡
ğ‘‡
ğ‘…
A=
MTTS+MTTR
MTTS
	â€‹

 for various MTTR	Line graph
Validation Comparison	SPC vs. PHM recall or reliability performance (bar chart)	Bar graph
Commentary	Text: â€œModel achieves PHM-equivalent reliability behavior using SPC data.â€	Text summary

âœ… Outcome: Shows your model mimics PHM system behavior without sensors or new infrastructure.

ğŸ”¹ Panel 4: RQ3 â€“ Operational Impact (Scrap, TTE, ROI)

Research Link:
RQ3: What measurable reduction in scrap rate, economic cost, and TTE consumption can be achieved?
H3: Predictive reliability model yields â‰¥20% scrap reduction, â‰¥10% TTE recovery, â‰¥2Ã— ROI.

Purpose

To demonstrate impact â€” not just predictions, but measurable industrial outcomes.

Contents
Section	Description	Display Element
Scrap Reduction	Before vs. Predicted Scrap %	Bar chart
TTE Savings	Energy saved (kWh or %) based on DOE factors	Gauge or number
ROI	Cost savings vs. baseline (e.g., $/yr)	Card
COâ‚‚ Reduction	Emission savings based on TTE recovery	Card
Summary Text	â€œValidated predictive reliability model achieved measurable DOE-aligned outcomes.â€	Text

âœ… Outcome: Connects your model to real-world industrial benefits â€” what the board and foundry manager both care about most.

ğŸ§© Technical Streamlining Summary
Task	Action
Remove Sidebar	Replace with compact top navigation tabs.
Auto-set Scrap Threshold	Script computes average scrap % per part ID on load.
Hide Rolling Window Controls	Keep active in backend but invisible to user.
Default Reliability Metrics	MTTR=1.0, Availability and R(t) calculated automatically.
Simplify Outputs	Only show: Scrap %, MTTS, R(1), R(5), Î», A, Cost, TTE, ROI.
Show Only Top 3 Defects/Processes	Too many features overwhelm both audiences.
Color scheme:	Blue = reliability, Green = efficiency, Gray = validation.

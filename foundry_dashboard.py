# -*- coding: utf-8 -*-
"""foundry_dashboard.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fahjSNm8n_UtDeEz74IOjBcTZuzpxepK
"""

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor

# Load and clean data
df = pd.read_csv("anonymized_parts.csv")

# Normalize column names
df.columns = df.columns.str.strip().str.lower().str.replace(" ", "_")

# Drop rows with missing critical values
required_cols = ["part_id", "scrap%", "order_quantity", "piece_weight_(lbs)"]
df = df.dropna(subset=required_cols)

# Train model using Part ID directly
features = ["order_quantity", "piece_weight_(lbs)", "part_id"]
X = df[features]
y = df["scrap%"]
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X, y)

# Dashboard UI
st.title("ðŸ§ª Foundry Scrap Risk Predictor")
st.markdown("Enter part details to estimate scrap risk and likely defects.")

part_id = st.number_input("Part ID", min_value=1, step=1)
quantity = st.number_input("Number of Parts", min_value=1, step=1)
weight = st.number_input("Weight per Part (lbs)", min_value=0.1, step=0.1)

if st.button("Predict Scrap Risk"):
    part_known = part_id in df["part_id"].values

    if part_known:
        input_data = pd.DataFrame([[quantity, weight, part_id]], columns=features)
        predicted_scrap = model.predict(input_data)[0]

        # Get top defect types historically associated with this part
        defect_cols = [col for col in df.columns if col.endswith("rate") and "scrap" not in col]
        part_df = df[df["part_id"] == part_id]
        defect_means = part_df[defect_cols].mean().sort_values(ascending=False).head(3)

        st.success("âœ… Known Part")
        st.metric("Predicted Scrap %", f"{round(predicted_scrap, 2)}%")
        st.write("Likely Defects:", ", ".join(defect_means.index.tolist()))

    else:
        similar = df[(df["piece_weight_(lbs)"].between(weight * 0.9, weight * 1.1)) &
                     (df["order_quantity"].between(quantity * 0.9, quantity * 1.1))]

        if not similar.empty:
            avg_scrap = similar["scrap%"].mean()
            defect_means = similar[[col for col in df.columns if col.endswith("rate") and "scrap" not in col]].mean()
            top_defects = defect_means.sort_values(ascending=False).head(3).index.tolist()
        else:
            avg_scrap = df["scrap%"].mean()
            defect_means = df[[col for col in df.columns if col.endswith("rate") and "scrap" not in col]].mean()
            top_defects = defect_means.sort_values(ascending=False).head(3).index.tolist()

        st.warning("ðŸ†• New Part")
        st.metric("Estimated Scrap %", f"{round(avg_scrap, 2)}%")
        st.write("Likely Defects:", ", ".join(top_defects))

    # Scrap weight and cost impact
    scrap_rate = predicted_scrap if part_known else avg_scrap
    scrap_weight = quantity * weight * (scrap_rate / 100)
    st.write(f"Estimated Scrap Weight: **{round(scrap_weight, 2)} lbs**")

    # Hypothetical cost (material + melting + labor)
    cost_estimate = scrap_weight * (0.75 + 0.15) + quantity * (scrap_rate / 100) * 2.00
    st.write(f"Hypothetical Cost Impact: **${round(cost_estimate, 2)}**")